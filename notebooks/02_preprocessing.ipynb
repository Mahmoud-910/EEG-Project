{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60203ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EEG Person Identification - Preprocessing Pipeline\n",
    "PhysioNet Motor Movement/Imagery Dataset\n",
    "Author: [Your Name]\n",
    "Date: 2025\n",
    "\n",
    "This notebook handles:\n",
    "1. Loading EDF files from PhysioNet dataset\n",
    "2. Bandpass filtering (8-30 Hz)\n",
    "3. Epoch extraction and segmentation\n",
    "4. Artifact removal\n",
    "5. Spectrogram generation\n",
    "6. Data normalization and saving\n",
    "\"\"\"\n",
    "\n",
    "#%% Import Required Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, filtfilt, stft\n",
    "import mne\n",
    "from mne.io import read_raw_edf\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"MNE version: {mne.__version__}\")\n",
    "\n",
    "#%% Configuration and Parameters\n",
    "class Config:\n",
    "    \"\"\"Configuration parameters for preprocessing\"\"\"\n",
    "    # Paths\n",
    "    RAW_DATA_DIR = './data/raw/files/'  # Path to extracted PhysioNet data\n",
    "    PROCESSED_DATA_DIR = './data/processed/'\n",
    "    SPECTROGRAM_DIR = './data/spectrograms/'\n",
    "    \n",
    "    # Signal processing parameters\n",
    "    SAMPLING_RATE = 160  # Hz (PhysioNet dataset sampling rate)\n",
    "    LOWCUT = 8.0  # Hz (lower bound of mu and beta bands)\n",
    "    HIGHCUT = 30.0  # Hz (upper bound of beta band)\n",
    "    FILTER_ORDER = 5\n",
    "    \n",
    "    # Epoch parameters\n",
    "    EPOCH_DURATION = 3.0  # seconds\n",
    "    EPOCH_SAMPLES = int(EPOCH_DURATION * SAMPLING_RATE)  # 480 samples\n",
    "    \n",
    "    # Spectrogram parameters\n",
    "    NPERSEG = 64  # Window length for STFT\n",
    "    NOVERLAP = 32  # Overlap between windows\n",
    "    NFFT = 128  # Number of FFT points\n",
    "    \n",
    "    # Dataset parameters\n",
    "    N_SUBJECTS = 109\n",
    "    N_CHANNELS = 64\n",
    "    \n",
    "    # Task runs to use (motor imagery tasks)\n",
    "    # Runs 4, 8, 12: Imagery left vs right fist\n",
    "    # Runs 6, 10, 14: Imagery both fists vs both feet\n",
    "    TASK_RUNS = [4, 6, 8, 10, 12, 14]\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "    os.makedirs(SPECTROGRAM_DIR, exist_ok=True)\n",
    "\n",
    "config = Config()\n",
    "print(\"\\nConfiguration loaded:\")\n",
    "print(f\"  Sampling Rate: {config.SAMPLING_RATE} Hz\")\n",
    "print(f\"  Filter Band: {config.LOWCUT}-{config.HIGHCUT} Hz\")\n",
    "print(f\"  Epoch Duration: {config.EPOCH_DURATION} seconds ({config.EPOCH_SAMPLES} samples)\")\n",
    "\n",
    "#%% Helper Functions\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    \"\"\"\n",
    "    Apply Butterworth bandpass filter to EEG data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : ndarray, shape (n_channels, n_samples)\n",
    "        Raw EEG data\n",
    "    lowcut : float\n",
    "        Lower frequency bound (Hz)\n",
    "    highcut : float\n",
    "        Upper frequency bound (Hz)\n",
    "    fs : float\n",
    "        Sampling frequency (Hz)\n",
    "    order : int\n",
    "        Filter order\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    filtered_data : ndarray\n",
    "        Bandpass filtered EEG data\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    filtered_data = filtfilt(b, a, data, axis=1)\n",
    "    return filtered_data\n",
    "\n",
    "def extract_epochs(raw, events, epoch_duration, event_ids):\n",
    "    \"\"\"\n",
    "    Extract epochs around task events\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    raw : mne.io.Raw\n",
    "        Raw EEG object\n",
    "    events : ndarray\n",
    "        Event array from MNE\n",
    "    epoch_duration : float\n",
    "        Duration of each epoch in seconds\n",
    "    event_ids : dict\n",
    "        Event ID mapping\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    epochs_data : ndarray, shape (n_epochs, n_channels, n_samples)\n",
    "        Extracted epochs\n",
    "    labels : ndarray\n",
    "        Task labels for each epoch\n",
    "    \"\"\"\n",
    "    tmin, tmax = 0.0, epoch_duration\n",
    "    epochs = mne.Epochs(raw, events, event_id=event_ids, tmin=tmin, tmax=tmax,\n",
    "                        baseline=None, preload=True, verbose=False)\n",
    "    \n",
    "    epochs_data = epochs.get_data()  # Shape: (n_epochs, n_channels, n_samples)\n",
    "    labels = epochs.events[:, -1]  # Event IDs\n",
    "    \n",
    "    return epochs_data, labels\n",
    "\n",
    "def compute_spectrogram(epoch_data, fs, nperseg=64, noverlap=32, nfft=128):\n",
    "    \"\"\"\n",
    "    Compute spectrogram for a single epoch\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    epoch_data : ndarray, shape (n_channels, n_samples)\n",
    "        Single epoch data\n",
    "    fs : float\n",
    "        Sampling frequency\n",
    "    nperseg : int\n",
    "        Length of each segment for STFT\n",
    "    noverlap : int\n",
    "        Number of overlapping samples\n",
    "    nfft : int\n",
    "        Number of FFT points\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    spectrogram : ndarray, shape (n_channels, n_frequencies, n_time_bins)\n",
    "        Time-frequency representation\n",
    "    \"\"\"\n",
    "    n_channels = epoch_data.shape[0]\n",
    "    \n",
    "    # Compute STFT for first channel to get dimensions\n",
    "    f, t, Zxx = stft(epoch_data[0], fs=fs, nperseg=nperseg, \n",
    "                     noverlap=noverlap, nfft=nfft)\n",
    "    \n",
    "    # Initialize spectrogram array\n",
    "    spectrogram = np.zeros((n_channels, len(f), len(t)))\n",
    "    \n",
    "    # Compute STFT for all channels\n",
    "    for ch in range(n_channels):\n",
    "        f, t, Zxx = stft(epoch_data[ch], fs=fs, nperseg=nperseg,\n",
    "                        noverlap=noverlap, nfft=nfft)\n",
    "        spectrogram[ch] = np.abs(Zxx)\n",
    "    \n",
    "    return spectrogram\n",
    "\n",
    "def normalize_data(data, method='zscore'):\n",
    "    \"\"\"\n",
    "    Normalize data using z-score normalization\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : ndarray\n",
    "        Data to normalize\n",
    "    method : str\n",
    "        Normalization method ('zscore' or 'minmax')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    normalized_data : ndarray\n",
    "        Normalized data\n",
    "    \"\"\"\n",
    "    if method == 'zscore':\n",
    "        mean = np.mean(data, axis=(0, 2), keepdims=True)\n",
    "        std = np.std(data, axis=(0, 2), keepdims=True) + 1e-8\n",
    "        normalized_data = (data - mean) / std\n",
    "    elif method == 'minmax':\n",
    "        min_val = np.min(data, axis=(0, 2), keepdims=True)\n",
    "        max_val = np.max(data, axis=(0, 2), keepdims=True)\n",
    "        normalized_data = (data - min_val) / (max_val - min_val + 1e-8)\n",
    "    else:\n",
    "        normalized_data = data\n",
    "    \n",
    "    return normalized_data\n",
    "\n",
    "def remove_bad_epochs(epochs_data, threshold=5.0):\n",
    "    \"\"\"\n",
    "    Remove epochs with extreme amplitudes (artifacts)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    epochs_data : ndarray, shape (n_epochs, n_channels, n_samples)\n",
    "        Epoch data\n",
    "    threshold : float\n",
    "        Z-score threshold for artifact detection\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    clean_indices : ndarray\n",
    "        Indices of clean epochs\n",
    "    \"\"\"\n",
    "    # Calculate peak-to-peak amplitude for each epoch\n",
    "    ptp = np.ptp(epochs_data, axis=2)  # Shape: (n_epochs, n_channels)\n",
    "    max_ptp = np.max(ptp, axis=1)  # Max across channels\n",
    "    \n",
    "    # Calculate z-scores\n",
    "    z_scores = (max_ptp - np.mean(max_ptp)) / (np.std(max_ptp) + 1e-8)\n",
    "    \n",
    "    # Keep epochs below threshold\n",
    "    clean_indices = np.where(np.abs(z_scores) < threshold)[0]\n",
    "    \n",
    "    return clean_indices\n",
    "\n",
    "#%% Load and Process Single Subject\n",
    "\n",
    "def process_subject(subject_id, config):\n",
    "    \"\"\"\n",
    "    Process all runs for a single subject\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    subject_id : int\n",
    "        Subject ID (1-109)\n",
    "    config : Config\n",
    "        Configuration object\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    subject_data : dict\n",
    "        Dictionary containing processed data for the subject\n",
    "    \"\"\"\n",
    "    print(f\"\\nProcessing Subject {subject_id:03d}...\")\n",
    "    \n",
    "    all_epochs = []\n",
    "    all_spectrograms = []\n",
    "    all_tasks = []\n",
    "    \n",
    "    for run in config.TASK_RUNS:\n",
    "        # Construct filename (format: S001R04.edf)\n",
    "        filename = f\"S{subject_id:03d}R{run:02d}.edf\"\n",
    "        filepath = os.path.join(config.RAW_DATA_DIR, filename)\n",
    "        \n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"  Warning: {filename} not found, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Load EDF file\n",
    "            raw = read_raw_edf(filepath, preload=True, verbose=False)\n",
    "            \n",
    "            # Get data and apply bandpass filter\n",
    "            data = raw.get_data()  # Shape: (n_channels, n_samples)\n",
    "            filtered_data = bandpass_filter(data, config.LOWCUT, config.HIGHCUT, \n",
    "                                          config.SAMPLING_RATE, config.FILTER_ORDER)\n",
    "            \n",
    "            # Create new raw object with filtered data\n",
    "            info = raw.info\n",
    "            raw_filtered = mne.io.RawArray(filtered_data, info, verbose=False)\n",
    "            \n",
    "            # Find events\n",
    "            events = mne.find_events(raw_filtered, stim_channel='STI 014', \n",
    "                                    shortest_event=1, verbose=False)\n",
    "            \n",
    "            if len(events) == 0:\n",
    "                print(f\"  Warning: No events found in {filename}, skipping...\")\n",
    "                continue\n",
    "            \n",
    "            # Event IDs: T0=rest, T1=left, T2=right (or T1=hands, T2=feet)\n",
    "            event_ids = {'T1': 1, 'T2': 2}\n",
    "            \n",
    "            # Extract epochs\n",
    "            epochs_data, labels = extract_epochs(raw_filtered, events, \n",
    "                                                config.EPOCH_DURATION, event_ids)\n",
    "            \n",
    "            # Remove bad epochs\n",
    "            clean_indices = remove_bad_epochs(epochs_data, threshold=5.0)\n",
    "            epochs_data = epochs_data[clean_indices]\n",
    "            labels = labels[clean_indices]\n",
    "            \n",
    "            print(f\"  Run {run:02d}: {len(epochs_data)} clean epochs extracted\")\n",
    "            \n",
    "            # Compute spectrograms for each epoch\n",
    "            for epoch in epochs_data:\n",
    "                spectrogram = compute_spectrogram(epoch, config.SAMPLING_RATE,\n",
    "                                                 config.NPERSEG, config.NOVERLAP,\n",
    "                                                 config.NFFT)\n",
    "                all_spectrograms.append(spectrogram)\n",
    "            \n",
    "            all_epochs.append(epochs_data)\n",
    "            all_tasks.extend(labels)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {filename}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if len(all_epochs) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Concatenate all epochs\n",
    "    all_epochs = np.concatenate(all_epochs, axis=0)\n",
    "    all_spectrograms = np.array(all_spectrograms)\n",
    "    all_tasks = np.array(all_tasks)\n",
    "    \n",
    "    # Normalize data\n",
    "    all_epochs = normalize_data(all_epochs, method='zscore')\n",
    "    all_spectrograms = normalize_data(all_spectrograms, method='zscore')\n",
    "    \n",
    "    print(f\"  Total: {len(all_epochs)} epochs, {len(all_spectrograms)} spectrograms\")\n",
    "    print(f\"  Epoch shape: {all_epochs.shape}\")\n",
    "    print(f\"  Spectrogram shape: {all_spectrograms.shape}\")\n",
    "    \n",
    "    return {\n",
    "        'subject_id': subject_id,\n",
    "        'epochs': all_epochs,\n",
    "        'spectrograms': all_spectrograms,\n",
    "        'tasks': all_tasks,\n",
    "        'n_epochs': len(all_epochs)\n",
    "    }\n",
    "\n",
    "#%% Process All Subjects\n",
    "\n",
    "def process_all_subjects(config, start_subject=1, end_subject=109):\n",
    "    \"\"\"\n",
    "    Process all subjects in the dataset\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    config : Config\n",
    "        Configuration object\n",
    "    start_subject : int\n",
    "        First subject ID to process\n",
    "    end_subject : int\n",
    "        Last subject ID to process\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dataset : dict\n",
    "        Complete processed dataset\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PROCESSING ALL SUBJECTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    all_data = []\n",
    "    failed_subjects = []\n",
    "    \n",
    "    for subject_id in tqdm(range(start_subject, end_subject + 1), \n",
    "                          desc=\"Processing subjects\"):\n",
    "        subject_data = process_subject(subject_id, config)\n",
    "        \n",
    "        if subject_data is not None:\n",
    "            all_data.append(subject_data)\n",
    "        else:\n",
    "            failed_subjects.append(subject_id)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing Complete!\")\n",
    "    print(f\"  Successful: {len(all_data)} subjects\")\n",
    "    print(f\"  Failed: {len(failed_subjects)} subjects\")\n",
    "    if failed_subjects:\n",
    "        print(f\"  Failed IDs: {failed_subjects}\")\n",
    "    \n",
    "    return all_data, failed_subjects\n",
    "\n",
    "#%% Save Processed Data\n",
    "\n",
    "def save_processed_data(all_data, config):\n",
    "    \"\"\"\n",
    "    Save processed data to HDF5 file for efficient loading\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    all_data : list\n",
    "        List of subject data dictionaries\n",
    "    config : Config\n",
    "        Configuration object\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SAVING PROCESSED DATA\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Prepare data for saving\n",
    "    X_epochs = []\n",
    "    X_spectrograms = []\n",
    "    y_subjects = []\n",
    "    y_tasks = []\n",
    "    \n",
    "    for subject_data in all_data:\n",
    "        n_epochs = subject_data['n_epochs']\n",
    "        subject_id = subject_data['subject_id']\n",
    "        \n",
    "        X_epochs.append(subject_data['epochs'])\n",
    "        X_spectrograms.append(subject_data['spectrograms'])\n",
    "        y_subjects.extend([subject_id] * n_epochs)\n",
    "        y_tasks.extend(subject_data['tasks'])\n",
    "    \n",
    "    # Concatenate all data\n",
    "    X_epochs = np.concatenate(X_epochs, axis=0)\n",
    "    X_spectrograms = np.concatenate(X_spectrograms, axis=0)\n",
    "    y_subjects = np.array(y_subjects)\n",
    "    y_tasks = np.array(y_tasks)\n",
    "    \n",
    "    print(f\"\\nDataset Summary:\")\n",
    "    print(f\"  Total epochs: {len(X_epochs)}\")\n",
    "    print(f\"  Epochs shape: {X_epochs.shape}\")\n",
    "    print(f\"  Spectrograms shape: {X_spectrograms.shape}\")\n",
    "    print(f\"  Unique subjects: {len(np.unique(y_subjects))}\")\n",
    "    \n",
    "    # Save to HDF5\n",
    "    output_file = os.path.join(config.PROCESSED_DATA_DIR, 'eeg_processed_data.h5')\n",
    "    \n",
    "    with h5py.File(output_file, 'w') as hf:\n",
    "        hf.create_dataset('X_epochs', data=X_epochs, compression='gzip')\n",
    "        hf.create_dataset('X_spectrograms', data=X_spectrograms, compression='gzip')\n",
    "        hf.create_dataset('y_subjects', data=y_subjects, compression='gzip')\n",
    "        hf.create_dataset('y_tasks', data=y_tasks, compression='gzip')\n",
    "        \n",
    "        # Save metadata\n",
    "        hf.attrs['n_subjects'] = len(np.unique(y_subjects))\n",
    "        hf.attrs['n_epochs'] = len(X_epochs)\n",
    "        hf.attrs['n_channels'] = config.N_CHANNELS\n",
    "        hf.attrs['sampling_rate'] = config.SAMPLING_RATE\n",
    "        hf.attrs['epoch_duration'] = config.EPOCH_DURATION\n",
    "        hf.attrs['lowcut'] = config.LOWCUT\n",
    "        hf.attrs['highcut'] = config.HIGHCUT\n",
    "    \n",
    "    print(f\"\\n✓ Data saved to: {output_file}\")\n",
    "    print(f\"  File size: {os.path.getsize(output_file) / (1024**3):.2f} GB\")\n",
    "    \n",
    "    return X_epochs, X_spectrograms, y_subjects, y_tasks\n",
    "\n",
    "#%% Visualization Functions\n",
    "\n",
    "def visualize_sample_data(X_epochs, X_spectrograms, y_subjects, config):\n",
    "    \"\"\"\n",
    "    Create visualizations of sample processed data\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CREATING VISUALIZATIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Select a random sample\n",
    "    sample_idx = np.random.randint(0, len(X_epochs))\n",
    "    sample_epoch = X_epochs[sample_idx]\n",
    "    sample_spec = X_spectrograms[sample_idx]\n",
    "    sample_subject = y_subjects[sample_idx]\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    # Plot 1: Raw EEG signals (first 8 channels)\n",
    "    ax1 = plt.subplot(3, 2, 1)\n",
    "    time = np.arange(config.EPOCH_SAMPLES) / config.SAMPLING_RATE\n",
    "    for ch in range(8):\n",
    "        plt.plot(time, sample_epoch[ch] + ch*2, label=f'Ch{ch+1}', alpha=0.7)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Channel')\n",
    "    plt.title(f'Sample EEG Epoch (Subject {sample_subject})')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Spectrogram for one channel\n",
    "    ax2 = plt.subplot(3, 2, 2)\n",
    "    plt.imshow(sample_spec[0], aspect='auto', origin='lower', cmap='viridis')\n",
    "    plt.colorbar(label='Power')\n",
    "    plt.xlabel('Time bins')\n",
    "    plt.ylabel('Frequency bins')\n",
    "    plt.title('Sample Spectrogram (Channel 1)')\n",
    "    \n",
    "    # Plot 3: Distribution of subjects\n",
    "    ax3 = plt.subplot(3, 2, 3)\n",
    "    subject_counts = pd.Series(y_subjects).value_counts().sort_index()\n",
    "    plt.bar(subject_counts.index, subject_counts.values, alpha=0.7, color='steelblue')\n",
    "    plt.xlabel('Subject ID')\n",
    "    plt.ylabel('Number of Epochs')\n",
    "    plt.title('Epochs per Subject')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Frequency spectrum\n",
    "    ax4 = plt.subplot(3, 2, 4)\n",
    "    freqs = np.fft.rfftfreq(config.EPOCH_SAMPLES, 1/config.SAMPLING_RATE)\n",
    "    spectrum = np.abs(np.fft.rfft(sample_epoch[0]))\n",
    "    plt.plot(freqs, spectrum, color='coral', linewidth=2)\n",
    "    plt.xlim(0, 50)\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Power')\n",
    "    plt.title('Frequency Spectrum (Channel 1)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.axvline(config.LOWCUT, color='red', linestyle='--', alpha=0.5, label='Filter cutoff')\n",
    "    plt.axvline(config.HIGHCUT, color='red', linestyle='--', alpha=0.5)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot 5: Average spectrogram across channels\n",
    "    ax5 = plt.subplot(3, 2, 5)\n",
    "    avg_spec = np.mean(sample_spec, axis=0)\n",
    "    plt.imshow(avg_spec, aspect='auto', origin='lower', cmap='plasma')\n",
    "    plt.colorbar(label='Averaged Power')\n",
    "    plt.xlabel('Time bins')\n",
    "    plt.ylabel('Frequency bins')\n",
    "    plt.title('Average Spectrogram (All Channels)')\n",
    "    \n",
    "    # Plot 6: Channel correlation\n",
    "    ax6 = plt.subplot(3, 2, 6)\n",
    "    corr_matrix = np.corrcoef(sample_epoch)\n",
    "    plt.imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1, aspect='auto')\n",
    "    plt.colorbar(label='Correlation')\n",
    "    plt.xlabel('Channel')\n",
    "    plt.ylabel('Channel')\n",
    "    plt.title('Channel Correlation Matrix')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(config.PROCESSED_DATA_DIR, 'preprocessing_visualization.png'), \n",
    "                dpi=300, bbox_inches='tight')\n",
    "    print(\"\\n✓ Visualization saved!\")\n",
    "    plt.show()\n",
    "\n",
    "#%% Main Execution\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EEG PERSON IDENTIFICATION - PREPROCESSING PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Check if raw data directory exists\n",
    "    if not os.path.exists(config.RAW_DATA_DIR):\n",
    "        print(f\"\\n❌ Error: Raw data directory not found: {config.RAW_DATA_DIR}\")\n",
    "        print(\"Please download the PhysioNet dataset and extract it to this location.\")\n",
    "        print(\"Download from: https://physionet.org/content/eegmmidb/get-zip/1.0.0/\")\n",
    "    else:\n",
    "        print(f\"\\n✓ Raw data directory found: {config.RAW_DATA_DIR}\")\n",
    "        \n",
    "        # Process all subjects\n",
    "        all_data, failed_subjects = process_all_subjects(config)\n",
    "        \n",
    "        if len(all_data) > 0:\n",
    "            # Save processed data\n",
    "            X_epochs, X_spectrograms, y_subjects, y_tasks = save_processed_data(all_data, config)\n",
    "            \n",
    "            # Create visualizations\n",
    "            visualize_sample_data(X_epochs, X_spectrograms, y_subjects, config)\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"PREPROCESSING COMPLETE!\")\n",
    "            print(\"=\"*60)\n",
    "            print(\"\\nNext step: Run 03_model_training.ipynb\")\n",
    "        else:\n",
    "            print(\"\\n❌ Error: No subjects were successfully processed!\")\n",
    "            print(\"Please check the raw data directory and file formats.\")\n",
    "\n",
    "#%% Summary Statistics\n",
    "\n",
    "\"\"\"\n",
    "PREPROCESSING SUMMARY\n",
    "=====================\n",
    "\n",
    "This notebook preprocessed the PhysioNet EEG Motor Movement/Imagery Dataset:\n",
    "\n",
    "1. Loaded 64-channel EEG recordings from 109 subjects\n",
    "2. Applied 8-30 Hz bandpass filter (mu and beta bands)\n",
    "3. Extracted 3-second epochs aligned to motor imagery tasks\n",
    "4. Removed artifacts using amplitude thresholding\n",
    "5. Generated time-frequency spectrograms using STFT\n",
    "6. Normalized data using z-score normalization\n",
    "7. Saved processed data in HDF5 format\n",
    "\n",
    "Output Files:\n",
    "- eeg_processed_data.h5: Contains all preprocessed data\n",
    "- preprocessing_visualization.png: Sample visualizations\n",
    "\n",
    "The processed data is now ready for model training!\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
